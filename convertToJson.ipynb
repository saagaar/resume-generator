{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adda1318",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 168\u001b[0m\n\u001b[1;32m    166\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Model returned invalid JSON:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m       \u001b[38;5;66;03m# print(result.content)\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[43mconvertCVToJson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# def applicantOverview(cv_file=\"cv/cv.json\", suggestion_file=\"cv/suggestions.json\", jd_file=\"cv/jd.txt\"):\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m#     \"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m#     Generate a tailored personal statement for a job application\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m#     show_question(ask_model())\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# applicantOverview();\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapplicantOverview\u001b[39m(cv_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv/cv.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, suggestion_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv/suggestions.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, jd_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv/jd.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# Conversation history (Q&A)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m, in \u001b[0;36mconvertCVToJson\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m schema \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersonal_information\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m   ],\n\u001b[1;32m     54\u001b[0m }\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# ‚öôÔ∏è Initialize OpenRouter model (via OpenAI-compatible client)\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai/gpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# can swap with other OpenRouter models\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://openrouter.ai/api/v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# üìù Prompt setup\u001b[39;00m\n\u001b[1;32m     65\u001b[0m system \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a strict JSON extractor.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:744\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m    738\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[1;32m    739\u001b[0m         )\n\u001b[1;32m    740\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_httpx_client(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_api_base, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_timeout)\n\u001b[1;32m    743\u001b[0m     }\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_client.py:130\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "from file_handler import extract_text\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "def convertCVToJson() -> None:\n",
    "  api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "  # api_base = os.getenv(\"OPENROUTER_API_BASE\", \"https://openrouter.ai/api/v1\")\n",
    "  # model = os.getenv(\"OPENROUTER_MODEL\", \"meta-llama/llama-3-8b-instruct\")\n",
    "  # Following steps to workout tomoorow\n",
    "  #1. Use ipynb to upload a file and save it to a destination\n",
    "  #2. Extract the content from pdf or docx\n",
    "  # 3. Convert it to json using LLM\n",
    "  # 4. Save the json to a file\n",
    "  # 5. use the content of json to rewrite the cover letter \n",
    "  resume_text = extract_text(\"cv/my_cv.pdf\")\n",
    "  # client = OpenAI()\n",
    "  from IPython.display import display\n",
    "\n",
    "  schema = {\n",
    "    \"personal_information\": {\n",
    "      \"name\": \"\",\n",
    "      \"email\": \"\",\n",
    "      \"phone\": \"\",\n",
    "      \"location\": \"\"\n",
    "    },\n",
    "    \"summary\": \"\",\n",
    "    \"skills\": [],\n",
    "    \"experience\": [\n",
    "      {\n",
    "        \"role\": \"\",\n",
    "        \"company\": \"\",\n",
    "        \"start_date\": \"\",\n",
    "        \"end_date\": \"\",\n",
    "        \"description\": []\n",
    "      }\n",
    "    ],\n",
    "    \"education\": [\n",
    "      {\n",
    "        \"degree\": \"\",\n",
    "        \"institution\": \"\",\n",
    "        \"year\": \"\"\n",
    "      }\n",
    "    ],\n",
    "  }\n",
    "\n",
    "  # ‚öôÔ∏è Initialize OpenRouter model (via OpenAI-compatible client)\n",
    "  llm = ChatOpenAI(\n",
    "      model=\"openai/gpt-4o-mini\",   # can swap with other OpenRouter models\n",
    "      api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "      base_url=\"https://openrouter.ai/api/v1\",\n",
    "      temperature=0\n",
    "  )\n",
    "\n",
    "  # üìù Prompt setup\n",
    "  system = \"You are a strict JSON extractor.\"\n",
    "  human_prompt = \"\"\"\n",
    "  Extract the following CV into this JSON schema: {schema_content}\n",
    "\n",
    "  Rules:\n",
    "  - Copy content exactly into the schema.\n",
    "  - Do not invent anything. Leave blank if missing.\n",
    "  - Only return valid JSON.\n",
    "\n",
    "  CV TEXT:\n",
    "  {resume_text}\n",
    "  \"\"\"\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", system),\n",
    "      (\"human\", human_prompt)\n",
    "  ])\n",
    "  chain = prompt | llm\n",
    "\n",
    "  # Run chain\n",
    "  result = chain.invoke({\"resume_text\": resume_text,\"schema_content\": json.dumps(schema, indent=2)})\n",
    "\n",
    "  # Parse model output\n",
    "  try:\n",
    "      if(result.content):\n",
    "        extracted_json = json.loads(result.content)\n",
    "        filename='cv/cv.json';\n",
    "        print(\"‚úÖ Extracted JSON:\")\n",
    "        print(json.dumps(extracted_json, indent=2)) \n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump(extracted_json, file, indent=2)\n",
    "      else:\n",
    "         print  (\"‚ùå No content returned from model\") \n",
    "      \n",
    "  except json.JSONDecodeError:\n",
    "      print(\"‚ùå Model returned invalid JSON:\")\n",
    "      print(result.content)\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def suggestionsOnSkillSetJson():\n",
    "  jd=(read_file('cv/jd.txt'))\n",
    "  skillset= {\n",
    "                \"resume_improvements\": \"string - general advice on content, structure, tone, formatting\",\n",
    "                \"skills_required\": [\"string\", \"string\", ...],\n",
    "                \"experience_examples\": [\"string\", \"string\", ...],\n",
    "                \"soft_skills\": [\"string\", \"string\", ...],\n",
    "                \"certifications\": [\"string\", \"string\", ...],\n",
    "                \"keywords_for_ATS\": [\"string\", \"string\", ...]\n",
    "              }\n",
    "  system = \"\"\"You are a strict JSON extractor.\n",
    "              Always return output as **valid JSON only** following this schema: \n",
    "              {skillset}\n",
    "            - Replace generic terms with industry-specific language.\n",
    "            - Keep sentences short and natural with transitional phrases, like a human career coach speaking directly.       \n",
    "            - Never include extra commentary outside the JSON.\n",
    "            - Never use Markdown, code blocks, or ```json fencing.\n",
    "            - Output raw JSON only.\n",
    "            \"\"\"\n",
    "  human_prompt=\"\"\"\n",
    "                You are a professional career coach with decades of HR and recruitment experience. \n",
    "                I want to apply for the following position:\n",
    "                {jd}\n",
    "              Please provide me with up-to-date information on the skills and qualifications usually required for this role,\n",
    "                examples of prior experience or work experience that would make me an exceptional candidate during a recruitment process for this role, \n",
    "              information on the soft skills, aptitudes and personality traits that employers are likely to recognize as valuable in this role, and suggestions for recognized certifications or training that would improve my chances of success \n",
    "              and \n",
    "              Suggest 5 keywords I should add to my resume to improve ATS compatibility in JSon format\n",
    "  \"\"\"\n",
    "  llm = ChatGoogleGenerativeAI(\n",
    "      model=\"gemini-2.5-flash\",\n",
    "      temperature=0,\n",
    "      max_tokens=None,\n",
    "      timeout=None,\n",
    "      max_retries=2,\n",
    "  )\n",
    "  finalprompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", system),\n",
    "      (\"human\", human_prompt)\n",
    "  ])\n",
    "  chain = finalprompt | llm\n",
    "\n",
    "  # Run chain\n",
    "  result = chain.invoke({\"jd\": jd,\"skillset\":skillset})\n",
    "  print(result)\n",
    "  content = result.content.strip()\n",
    "  try:\n",
    "        suggestions = json.loads(content)\n",
    "        filename='cv/suggestions.json';\n",
    "        print(suggestions)\n",
    "        print(json.dumps(suggestions, indent=2)) \n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump(suggestions, file, indent=2)\n",
    "  except json.JSONDecodeError:\n",
    "      print(json.JSONDecodeError)\n",
    "      print(\"‚ùå Model returned invalid JSON:\")\n",
    "      # print(result.content)\n",
    "convertCVToJson();\n",
    "\n",
    "# def applicantOverview(cv_file=\"cv/cv.json\", suggestion_file=\"cv/suggestions.json\", jd_file=\"cv/jd.txt\"):\n",
    "#     \"\"\"\n",
    "#     Generate a tailored personal statement for a job application\n",
    "#     using candidate CV, recruiter suggestions, and job description.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Load CV JSON\n",
    "#     with open(cv_file, \"r\") as f:\n",
    "#         cv_data = json.load(f)\n",
    "\n",
    "#     # Load suggestion JSON\n",
    "#     with open(suggestion_file, \"r\") as f:\n",
    "#         suggestion_data = json.load(f)\n",
    "\n",
    "#     # Load job description text\n",
    "#     with open(jd_file, \"r\") as f:\n",
    "#         jd_text = f.read().strip()\n",
    "\n",
    "#     # Build system instructions\n",
    "#     system = \"\"\"You are an expert resume analyst, career advisor, and HR professional specializing in the tech industry.\n",
    "# You have access to:\n",
    "# - cv.json (candidate skills, qualifications, and work history)\n",
    "# - suggestion.json (role-specific recruiter advice, skills, examples, certifications, ATS keywords)\n",
    "# - jd.txt (job description of the target role)\n",
    "\n",
    "# Instructions:\n",
    "# 1. Confirm you have processed the provided files.\n",
    "# 2. Ask the candidate clarifying questions one at a time to understand why they are the perfect fit.\n",
    "# 3. When you have enough information, generate a polished personal statement of up to 150 words:\n",
    "#    - Professional yet natural tone, not robotic.\n",
    "#    - Concise, attention-grabbing, and tailored to the job.\n",
    "#    - Showcase achievements, technical skills, and impact.\n",
    "#    - Seamlessly include ATS keywords from suggestion.json and relevant terms from jd.txt.\n",
    "#    - Align tone with the company‚Äôs values and role requirements.\n",
    "# Do not create the statement until you have asked the essential questions you need.\n",
    "# \"\"\"\n",
    "\n",
    "#     human_template = \"\"\"\n",
    "# Candidate CV:\n",
    "# {cv_data}\n",
    "\n",
    "# Recruiter Suggestions:\n",
    "# {suggestion_data}\n",
    "\n",
    "# Job Description:\n",
    "# {jd_text}\n",
    "# \"\"\"\n",
    "\n",
    "#     # Create prompt\n",
    "#     finalprompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system),\n",
    "#         (\"human\", human_template)\n",
    "#     ])\n",
    "\n",
    "#     # Initialize model\n",
    "#     llm = ChatGoogleGenerativeAI(\n",
    "#         model=\"gemini-2.5-flash\",\n",
    "#         temperature=0.3,\n",
    "#         max_tokens=None,\n",
    "#         timeout=None,\n",
    "#         max_retries=2,\n",
    "#     )\n",
    "\n",
    "#     chain = finalprompt | llm\n",
    "\n",
    "#     # Run the chain\n",
    "#     result = chain.invoke({\n",
    "#         \"cv_data\": json.dumps(cv_data, indent=2),\n",
    "#         \"suggestion_data\": json.dumps(suggestion_data, indent=2),\n",
    "#         \"jd_text\": jd_text\n",
    "#     })\n",
    "#     content = result.content.strip()\n",
    "#     while True:\n",
    "#         print(\"\\nü§ñ Assistant:\", content)\n",
    "\n",
    "#         # If model produced the final statement ‚Üí stop\n",
    "#         if \"FINAL_STATEMENT:\" in content:\n",
    "#             break\n",
    "\n",
    "#         display(\"Your Answer: \")\n",
    "#         user_input = input()\n",
    "#         # Otherwise, wait for your input\n",
    "#         user_input = input(\"\\n‚úçÔ∏è Your Answer: \")\n",
    "\n",
    "#         # Send answer back into conversation\n",
    "#         content = llm.invoke(user_input).content\n",
    "#         return result.content\n",
    "\n",
    "# def applicantOverview(cv_file=\"cv/cv.json\", suggestion_file=\"cv/suggestions.json\", jd_file=\"cv/jd.txt\"):\n",
    "#     # Load candidate files\n",
    "#     with open(cv_file, \"r\") as f:\n",
    "#         cv_data = json.load(f)\n",
    "#     with open(suggestion_file, \"r\") as f:\n",
    "#         suggestion_data = json.load(f)\n",
    "#     with open(jd_file, \"r\") as f:\n",
    "#         jd_text = f.read().strip()\n",
    "\n",
    "#     # Conversation history\n",
    "#     conversation_history = []\n",
    "\n",
    "#     # Initialize LLM\n",
    "#     llm = ChatGoogleGenerativeAI(\n",
    "#         model=\"gemini-2.5-flash\",\n",
    "#         temperature=0.3,\n",
    "#         max_tokens=None,\n",
    "#         timeout=None,\n",
    "#         max_retries=2,\n",
    "#     )\n",
    "\n",
    "#     # System prompt for the LLM\n",
    "#     system_prompt = \"\"\"You are an expert resume analyst and HR professional in tech.\n",
    "# You have access to:\n",
    "# - Candidate CV (skills, achievements)\n",
    "# - Recruiter suggestions (role-specific advice, ATS keywords)\n",
    "# - Job description\n",
    "# Task:\n",
    "# 1. Ask the candidate clarifying questions one at a time to collect information for a personal statement.\n",
    "# 2. Only ask questions you need to generate a polished 150-word personal statement.\n",
    "# 3. Wait for candidate‚Äôs answer before asking the next question.\n",
    "# 4. Once you have enough info, output the final statement starting with \"FINAL_STATEMENT:\".\n",
    "# 5. Include relevant ATS keywords. Use a professional but human tone.\n",
    "# \"\"\"\n",
    "\n",
    "#     # Function to ask the model for next question or final statement\n",
    "#     def ask_model():\n",
    "#         # Build prompt with embedded JSON and conversation history\n",
    "#         history_text = \"\"\n",
    "#         for i, msg in enumerate(conversation_history):\n",
    "#             history_text += f\"Q{i+1}: {msg['question']}\\nA{i+1}: {msg['answer']}\\n\"\n",
    "\n",
    "#         human_prompt = f\"\"\"\n",
    "# Candidate CV:\n",
    "# {json.dumps(cv_data, indent=2)}\n",
    "\n",
    "# Recruiter Suggestions:\n",
    "# {json.dumps(suggestion_data, indent=2)}\n",
    "\n",
    "# Job Description:\n",
    "# {jd_text}\n",
    "\n",
    "# Conversation so far:\n",
    "# {history_text}\n",
    "\n",
    "# Please generate the next question for the candidate, or output FINAL_STATEMENT: if you have enough information.\n",
    "# \"\"\"\n",
    "#         finalprompt = ChatPromptTemplate.from_messages([\n",
    "#             (\"system\", system_prompt),\n",
    "#             (\"human\", human_prompt)\n",
    "#         ])\n",
    "\n",
    "#         response = llm.invoke(human_prompt)  # human_prompt is a string\n",
    "#         return response.content\n",
    "\n",
    "#     # Function to display question and text box\n",
    "#     def show_question(response_text):\n",
    "#         clear_output()\n",
    "#         if response_text.startswith(\"FINAL_STATEMENT:\"):\n",
    "#             # Print final personal statement\n",
    "#             print(\"üìù Personal Statement Generated:\\n\")\n",
    "#             print(response_text.replace(\"FINAL_STATEMENT:\", \"\").strip())\n",
    "#             return\n",
    "\n",
    "#         # Show question to user\n",
    "#         print(\"ü§ñ\", response_text)\n",
    "#         text_box = widgets.Textarea(\n",
    "#             placeholder='Type your answer here...',\n",
    "#             layout=widgets.Layout(width='100%', height='100px')\n",
    "#         )\n",
    "#         submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "#         def on_submit(b):\n",
    "#             # Save answer\n",
    "#             print('button is submitted')\n",
    "#             conversation_history.append({\"question\": response_text, \"answer\": text_box.value})\n",
    "#             # Ask next question\n",
    "#             show_question(ask_model())\n",
    "\n",
    "#         submit_button.on_click(on_submit)\n",
    "#         display(text_box, submit_button)\n",
    "\n",
    "#     # Start the interactive loop\n",
    "#     show_question(ask_model())\n",
    "# applicantOverview();\n",
    "\n",
    "def applicantOverview(cv_file=\"cv/cv.json\", suggestion_file=\"cv/suggestions.json\", jd_file=\"cv/jd.txt\"):\n",
    "    # Conversation history (Q&A)\n",
    "    conversation_history = []\n",
    "    with open(cv_file, \"r\") as f:\n",
    "        cv_data = json.load(f)\n",
    "    with open(suggestion_file, \"r\") as f:\n",
    "        suggestion_data = json.load(f)\n",
    "    with open(jd_file, \"r\") as f:\n",
    "        jd_text = f.read().strip()\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    "    # System prompt for the LLM\n",
    "    system_prompt =\"\"\"You are an expert resume analyst and HR professional in tech.\n",
    "    You have access to:\n",
    "    - Candidate CV (skills, achievements)\n",
    "    - Recruiter suggestions (role-specific advice, ATS keywords)\n",
    "    - Job description\n",
    "    Task:\n",
    "    1. Ask the candidate clarifying questions one at a time to collect information for a personal statement.\n",
    "    2. Only ask questions you need to generate a polished 150-word personal statement.\n",
    "    3. Wait for candidate‚Äôs answer before asking the next question.\n",
    "    4. Once you have enough info, output the final statement starting with \"FINAL_STATEMENT:\".\n",
    "    5. Include relevant ATS keywords. Use a professional but human tone.\n",
    "    \"\"\"\n",
    "\n",
    "    def ask_model():\n",
    "        # Merge everything into one context\n",
    "        merged_context = {\n",
    "            \"cv_data\": cv_data,\n",
    "            \"suggestions\": suggestion_data,\n",
    "            \"job_description\": jd_text,\n",
    "            \"qna\": conversation_history\n",
    "        }\n",
    "        human_prompt = f\"\"\"\n",
    "        Here is all available information about the candidate:\n",
    "        {json.dumps(merged_context, indent=2)}\n",
    "        Please generate the next clarifying question for the candidate, or output FINAL_STATEMENT: if you have enough information.\n",
    "        \"\"\"\n",
    "        finalprompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", human_prompt)\n",
    "        ])\n",
    "\n",
    "        # ‚úÖ Use the structured prompt, not just the string\n",
    "        response = llm.invoke(finalprompt.format_messages())\n",
    "        return response.content\n",
    "\n",
    "    def show_question(response_text):\n",
    "        clear_output()\n",
    "        if response_text.startswith(\"FINAL_STATEMENT:\"):\n",
    "            # Print final personal statement\n",
    "            print(\"üìù Personal Statement Generated:\\n\")\n",
    "            print(response_text.replace(\"FINAL_STATEMENT:\", \"\").strip())\n",
    "\n",
    "            # Save combined context\n",
    "            final_context = {\n",
    "                \"cv_data\": cv_data,\n",
    "                \"suggestions\": suggestion_data,\n",
    "                \"job_description\": jd_text,\n",
    "                \"qna\": conversation_history,\n",
    "                \"final_statement\": response_text.replace(\"FINAL_STATEMENT:\", \"\").strip()\n",
    "            }\n",
    "            with open(\"application_context.json\", \"w\") as f:\n",
    "                json.dump(final_context, f, indent=2)\n",
    "\n",
    "            print(\"\\n‚úÖ Saved in application_context.json\")\n",
    "            return\n",
    "\n",
    "        # Show question\n",
    "        print(\"ü§ñ\", response_text)\n",
    "        text_box = widgets.Textarea(\n",
    "            placeholder='Type your answer here...',\n",
    "            layout=widgets.Layout(width='100%', height='100px')\n",
    "        )\n",
    "        submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "        def on_submit(b):\n",
    "            # Save Q&A\n",
    "            conversation_history.append({\"question\": response_text, \"answer\": text_box.value})\n",
    "            # Ask next question\n",
    "            show_question(ask_model())\n",
    "\n",
    "        submit_button.on_click(on_submit)\n",
    "        display(text_box, submit_button)\n",
    "\n",
    "    # Start interactive loop\n",
    "    show_question(ask_model())\n",
    "\n",
    "\n",
    "applicantOverview()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8ea84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
